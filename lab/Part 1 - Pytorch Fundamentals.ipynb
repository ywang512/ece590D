{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The material presented in this notebook is for using in Introduction to Deep Learning (CEE 690/ECE 590) course, Duke University, Fall 2019."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Modules and packages in Pytorch__\n",
    "* ### __torch :__  a Tensor library like Numpy, with strong GPU support\n",
    "* ### __torch.autograd :__ an automatic differentiation library that supports all differentiable Tensor operations in torch\n",
    "* ### __torch.nn :__ a neural networks library integrated with autograd\n",
    "* ### __torch.nn.functional :__ implementation of many useful mathematical functions such as Relu, Tanh, and so on.\n",
    "* ### __torch.optim :__ an optimization package to be used with torch.nn with standard optimization methods such as SGD, RMSProp, Adam, and so on.\n",
    "* ### __torch.multiprocessing :__ python multiprocessing, but with magical memory sharing of torch Tensors across processes. Useful for data loading and hogwild training.\n",
    "* ### __torch.utils :__ DataLoader, Trainer and other utility functions for convenience\n",
    "* ### __torchvision :__ consists of popular datasets, model architectures, and common image transformations for computer vision."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Importing modules and packages__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Diffferent level of abstractions__ \n",
    "* ### __Tensor:__ Like array in Numpy, but runs on a GPU to accelerate computing\n",
    "* ### __Module:__ A neural network layer --> storing states or learnable weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __Getting started with Tensors__ \n",
    "https://pytorch.org/docs/stable/tensors.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a 5x3 matrix, uninitialized:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.empty(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1.7405e+24,  8.8282e-43, -1.7405e+24],\n",
       "        [ 8.8282e-43, -1.7405e+24,  8.8282e-43],\n",
       "        [-1.7405e+24,  8.8282e-43, -1.7405e+24],\n",
       "        [ 8.8282e-43, -1.7405e+24,  8.8282e-43],\n",
       "        [-1.7405e+24,  8.8282e-43, -1.7405e+24]])"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a a randomly initialized $5\\times 3$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.rand(5, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7111, 0.2253, 0.3121],\n",
       "        [0.2034, 0.1472, 0.4908],\n",
       "        [0.0198, 0.3489, 0.1472],\n",
       "        [0.5495, 0.9788, 0.9325],\n",
       "        [0.2847, 0.0625, 0.9936]])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a zero matrix and of dtype long:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.zeros(5, 3, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0],\n",
       "        [0, 0, 0]])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a tensor from data (a 3-d tensor):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[[5.5, 3], [-3.8, 100]], [[1, 30], [023.8, 10]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[  5.5000,   3.0000],\n",
       "         [ -3.8000, 100.0000]],\n",
       "\n",
       "        [[  1.0000,  30.0000],\n",
       "         [ 23.8000,  10.0000]]])"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The size of a tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 2, 2])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a tensor based on an existing tensor. \n",
    "###  Reusing the properties of the input tensor, e.g. dtype, unless new values are provided by user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn_like(x, dtype=torch.float) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-1.0354, -0.6432],\n",
       "         [-0.0378, -0.1270]],\n",
       "\n",
       "        [[ 1.0058,  1.3536],\n",
       "         [-1.0403,  0.3718]]])"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting started with Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding to two tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.2444,  1.8104,  2.0608],\n",
       "        [ 1.0121,  1.1090,  0.4099],\n",
       "        [-0.5658,  2.5439,  1.0580],\n",
       "        [ 1.9664,  1.1493,  1.6734],\n",
       "        [-0.5262,  1.0086,  1.8097]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.randn(5,3)\n",
    "y = torch.ones(5,3)\n",
    "a = x + y\n",
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## item() to get the value as a Python number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.9974])\n",
      "0.997427225112915\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Converting a Torch Tensor to a NumPy array and vice versa\n",
    "https://pytorch.org/docs/stable/notes/cuda.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Tensor to Numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = torch.ones(5)\n",
    "x = a.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.], dtype=float32)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From Numpy to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1., 1., 1., 1., 1.])"
      ]
     },
     "execution_count": 160,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.ones(5)\n",
    "b = torch.from_numpy(a)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 1., 1., 1., 1.], dtype=torch.float64)"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix inner product (similar to np.dot() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.6189,  1.0974, -4.3025],\n",
       "        [ 0.9510, -1.4415, -3.0914]])"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.randn(2,3)\n",
    "b = torch.randn(3,3)\n",
    "torch.mm(a,b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing dimention with size 1 from a Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([5, 2, 1])\n",
      "torch.Size([5, 2])\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(5,2,1)\n",
    "print(a.size())\n",
    "b = torch.squeeze(a, dim= 2)\n",
    "print(b.size())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfering Tensors to different devices, e.g., GPU, CPU using the .to method.\n",
    "### To run on GPU, just cast tensors to a cuda data type!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First check if the CUDA interface exists on your system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")          # a CUDA device object\n",
    "    dtype = torch.cuda.FloatTensor         # casting tensors to a cuda data type\n",
    "else:\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Directly create a tensor on GPU, or use strings ``.to(\"cuda\")``"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = torch.ones_like(b, device=device, dtype=torch.float)  \n",
    "x = torch.randn(y.size()).to('cuda') # or .to(y.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.4831,  1.4877],\n",
      "        [-0.3847, -0.3739],\n",
      "        [ 0.9239,  0.2595],\n",
      "        [ 0.2597,  1.5604],\n",
      "        [ 0.9537,  2.0322]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "z = x + y\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AUTOGRAD: AUTOMATIC DIFFERENTIATION\n",
    "https://pytorch.org/docs/stable/autograd.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ### Central to all neural networks in PyTorch is the autograd package\n",
    "* ### Every Tensor has an attribute called __.requires_grad__ which can be True or False\n",
    "* ### When it is True, starts to track all operations on it\n",
    "* ### When finishing the computation, one can call __.backward()__ and have all the gradients computed automatically\n",
    "* ### The gradient for the tensors will be accumulated into __.grad__ attribute"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __To stop a tensor from tracking history:__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* ## First approach:\n",
    "###    - calling .detach() to detach it from the computation history\n",
    "###    - It also prevents future computation from being tracked\n",
    "\n",
    "* ## Second  approach:\n",
    "###   - wrap the code block using __with torch.no_grad()__ \n",
    "###   - Deactivating computation of the gradient for trainable parameters with __requires_grad=True__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Each tensor has a .grad_fn attribute that references a Function that has created the Tensor \n",
    "(grad_fn is None for Tensors created by the user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1.],\n",
       "        [1., 1.]], requires_grad=True)"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = torch.ones(2, 2, requires_grad=True)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Operating a function on x makes the resulting tensor have __grad_fn__ attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[3., 3.],\n",
       "        [3., 3.]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = x + 2\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### __requires_grad_(.)__ changes an existing Tensorâ€™s requires_grad flag in-place. \n",
    "### The input flag defaults to False if not given"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 1.],\n",
      "        [2., 3.]])\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "x = torch.arange(4).float().view(2,2)\n",
    "print(x)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "x.requires_grad_(True)\n",
    "print(x.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4430, 0.9717],\n",
      "        [0.4099, 0.6710],\n",
      "        [0.9164, 0.6877],\n",
      "        [0.0308, 0.3538],\n",
      "        [0.9659, 0.4145]])\n",
      "None\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "y = (x * x).sum()\n",
    "print(b)\n",
    "print(b.grad_fn)\n",
    "print(b.requires_grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]], grad_fn=<AddBackward0>)\n",
      "tensor(14., grad_fn=<SumBackward0>)\n",
      "tensor([[0., 2.],\n",
      "        [4., 6.]])\n"
     ]
    }
   ],
   "source": [
    "if x.grad is not None:\n",
    "    x.grad.zero_() # comment this line will accumulate gradients\n",
    "z = x + 2\n",
    "print(z)\n",
    "out = (x * x).sum()\n",
    "out.backward()\n",
    "print(out)\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3.],\n",
      "        [4., 5.]], grad_fn=<AddBackward0>)\n",
      "(tensor([[0., 2.],\n",
      "        [4., 6.]]),)\n"
     ]
    }
   ],
   "source": [
    "# to explicitly compute gradients\n",
    "z = x + 2\n",
    "print(z)\n",
    "out = (x * x).sum()\n",
    "x_grad = torch.autograd.grad(out,x)\n",
    "print(x_grad)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
